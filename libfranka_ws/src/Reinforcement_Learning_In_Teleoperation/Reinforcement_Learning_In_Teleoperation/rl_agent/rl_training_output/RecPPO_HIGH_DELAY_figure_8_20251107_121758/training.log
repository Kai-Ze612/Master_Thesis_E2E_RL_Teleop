2025-11-07 12:17:58 [INFO] __main__ - Run Name: RecPPO_HIGH_DELAY_figure_8_20251107_121758
2025-11-07 12:17:58 [INFO] __main__ - Output Directory: ./rl_training_output/RecPPO_HIGH_DELAY_figure_8_20251107_121758
2025-11-07 12:17:58 [INFO] __main__ - Training Configuration:
2025-11-07 12:17:58 [INFO] __main__ -   Delay Config: HIGH_DELAY
2025-11-07 12:17:58 [INFO] __main__ -   Trajectory Type: figure_8
2025-11-07 12:17:58 [INFO] __main__ -   Randomize Trajectory: False
2025-11-07 12:17:58 [INFO] __main__ -   Total Timesteps: 3,000,000
2025-11-07 12:17:58 [INFO] __main__ -   Random Seed: 50
2025-11-07 12:17:58 [INFO] __main__ - 
2025-11-07 12:17:58 [INFO] __main__ - Setting random seed: 50
2025-11-07 12:17:58 [INFO] __main__ - Random seeds set for NumPy, PyTorch, and CUDA
2025-11-07 12:17:58 [INFO] __main__ - 
2025-11-07 12:18:04 [INFO] __main__ -   Vectorized Environment: SubprocVecEnv
2025-11-07 12:18:04 [INFO] __main__ -   Number of Envs: 5
2025-11-07 12:18:04 [INFO] __main__ -   Observation Space: (134,)
2025-11-07 12:18:04 [INFO] __main__ -   Action Space: (7,)
2025-11-07 12:18:04 [INFO] __main__ - 
2025-11-07 12:18:04 [INFO] __main__ - Initializing Recurrent-PPO trainer...
2025-11-07 12:18:05 [INFO] __main__ -   Trainer: RecurrentPPOTrainer
2025-11-07 12:18:05 [INFO] __main__ -   Policy Parameters: 1,578,909
2025-11-07 12:18:05 [INFO] __main__ -   Checkpoint Directory: ./rl_training_output/RecPPO_HIGH_DELAY_figure_8_20251107_121758
2025-11-07 12:18:05 [INFO] __main__ - 
2025-11-07 12:18:05 [INFO] __main__ - ======================================================================
2025-11-07 12:18:05 [INFO] __main__ - Starting Training
2025-11-07 12:18:05 [INFO] __main__ - ======================================================================
2025-11-07 12:18:05 [INFO] __main__ - 
2025-11-07 12:18:05 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Tensorboard login: http://localhost:6006/
