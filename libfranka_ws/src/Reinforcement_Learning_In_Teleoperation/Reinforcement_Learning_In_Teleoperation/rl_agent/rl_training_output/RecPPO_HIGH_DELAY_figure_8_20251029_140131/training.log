2025-10-29 14:01:31 [INFO] __main__ - Run Name: RecPPO_HIGH_DELAY_figure_8_20251029_140131
2025-10-29 14:01:31 [INFO] __main__ - Output Directory: ./rl_training_output/RecPPO_HIGH_DELAY_figure_8_20251029_140131
2025-10-29 14:01:31 [INFO] __main__ - Training Configuration:
2025-10-29 14:01:31 [INFO] __main__ -   Delay Config: HIGH_DELAY
2025-10-29 14:01:31 [INFO] __main__ -   Trajectory Type: figure_8
2025-10-29 14:01:31 [INFO] __main__ -   Randomize Trajectory: False
2025-10-29 14:01:31 [INFO] __main__ -   Total Timesteps: 2,000,000
2025-10-29 14:01:31 [INFO] __main__ -   Random Seed: None (random)
2025-10-29 14:01:31 [INFO] __main__ - 
2025-10-29 14:01:39 [INFO] __main__ -   Vectorized Environment: SubprocVecEnv
2025-10-29 14:01:39 [INFO] __main__ -   Number of Envs: 5
2025-10-29 14:01:39 [INFO] __main__ -   Observation Space: (134,)
2025-10-29 14:01:39 [INFO] __main__ -   Action Space: (7,)
2025-10-29 14:01:39 [INFO] __main__ - 
2025-10-29 14:01:39 [INFO] __main__ - Initializing Recurrent-PPO trainer...
2025-10-29 14:01:40 [INFO] __main__ -   Trainer: RecurrentPPOTrainer
2025-10-29 14:01:40 [INFO] __main__ -   Policy Parameters: 1,052,573
2025-10-29 14:01:40 [INFO] __main__ -   Checkpoint Directory: ./rl_training_output/RecPPO_HIGH_DELAY_figure_8_20251029_140131
2025-10-29 14:01:40 [INFO] __main__ - 
2025-10-29 14:01:40 [INFO] __main__ - ======================================================================
2025-10-29 14:01:40 [INFO] __main__ - Starting Training
2025-10-29 14:01:40 [INFO] __main__ - ======================================================================
2025-10-29 14:01:40 [INFO] __main__ - 
2025-10-29 14:01:40 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Tensorboard login: http://localhost:6006/
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm - 
──────────────────────────────────────────────────────────────────────
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm - Update: 10/200 | Timesteps: 100,000 | Elapsed: 0:30:16
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm - ──────────────────────────────────────────────────────────────────────
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Avg Rollout Reward: 1201.741
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Actor Loss: -0.0028 | Critic Loss: 0.1495
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Prediction Loss: 0.026579
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Entropy: 5.6479 | Approx KL: 0.00957
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm -   Collect Time: 68.66s | Update Time: 129.82s | FPS: 50
2025-10-29 14:31:57 [INFO] Reinforcement_Learning_In_Teleoperation.rl_agent.ppo_training_algorithm - 
  ✓ Early Stopping: New best reward 1201.741 (+inf). Saving model.
