2025-12-11 20:56:25 [INFO] __main__ - Training Configuration (Joint End-to-End):
2025-12-11 20:56:25 [INFO] __main__ -   Delay: HIGH_VARIANCE
2025-12-11 20:56:25 [INFO] __main__ -   Trajectory: figure_8
2025-12-11 20:56:25 [INFO] __main__ -   Total Timesteps: 30000000
2025-12-11 20:56:25 [INFO] __main__ - Creating vectorized environment...
2025-12-11 20:56:27 [INFO] __main__ - Initializing SACTrainer...
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Initial alpha: 1.0000
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Tensorboard logs at: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_205625/tensorboard_sac
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting SAC Training with SHARED ENCODER (Fixed Version)
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Obs Dim: 2334 | Output Dim: 7
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Stage 1 (Encoder + Critic Warmup): 20000 steps
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Stage 2 (RL with Frozen Encoder, Delayed Policy): remaining steps
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Policy Delay: 2
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Initial Alpha: 1.0000
2025-12-11 20:56:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:57:09 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 2000/20000] Aux Loss: 0.000335 | Critic Loss: 0.7535
2025-12-11 20:57:46 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 3000/20000] Aux Loss: 0.000200 | Critic Loss: 0.6879
2025-12-11 20:58:23 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 4000/20000] Aux Loss: 0.000119 | Critic Loss: 0.7828
2025-12-11 20:59:01 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 5000/20000] Aux Loss: 0.000125 | Critic Loss: 1.3293
2025-12-11 20:59:40 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 6000/20000] Aux Loss: 0.000124 | Critic Loss: 0.8266
2025-12-11 21:00:18 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 7000/20000] Aux Loss: 0.000124 | Critic Loss: 1.0821
2025-12-11 21:00:57 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 8000/20000] Aux Loss: 0.000116 | Critic Loss: 1.9613
2025-12-11 21:01:35 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 9000/20000] Aux Loss: 0.000107 | Critic Loss: 1.8504
2025-12-11 21:02:13 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 10000/20000] Aux Loss: 0.000116 | Critic Loss: 2.2700
2025-12-11 21:02:50 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 11000/20000] Aux Loss: 0.000109 | Critic Loss: 2.5450
2025-12-11 21:03:27 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 12000/20000] Aux Loss: 0.000206 | Critic Loss: 2.1462
2025-12-11 21:04:06 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 13000/20000] Aux Loss: 0.000324 | Critic Loss: 2.6243
2025-12-11 21:04:47 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 14000/20000] Aux Loss: 0.000124 | Critic Loss: 3.0206
2025-12-11 21:05:27 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 15000/20000] Aux Loss: 0.000197 | Critic Loss: 3.7540
2025-12-11 21:06:08 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 16000/20000] Aux Loss: 0.000131 | Critic Loss: 4.3263
2025-12-11 21:06:47 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 17000/20000] Aux Loss: 0.000095 | Critic Loss: 4.7033
2025-12-11 21:07:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 18000/20000] Aux Loss: 0.000091 | Critic Loss: 4.9570
2025-12-11 21:08:09 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 19000/20000] Aux Loss: 0.000110 | Critic Loss: 5.7232
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - FREEZING SHARED ENCODER - State Estimator training complete
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Trainable actor params: 847,118
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Trainable critic params: 1,694,722
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Frozen encoder params: 1,366,926
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Current alpha: 1.0000
2025-12-11 21:08:49 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting Validation...
2025-12-11 21:09:02 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 0: Avg Action Norm: 0.2903 | Avg Movement: 0.000118
2025-12-11 21:09:16 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 1: Avg Action Norm: 0.2904 | Avg Movement: 0.000118
2025-12-11 21:09:29 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 2: Avg Action Norm: 0.2903 | Avg Movement: 0.000118
2025-12-11 21:09:42 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 3: Avg Action Norm: 0.2904 | Avg Movement: 0.000118
2025-12-11 21:09:55 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 4: Avg Action Norm: 0.2905 | Avg Movement: 0.000118
2025-12-11 21:09:55 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Validation Reward: 2269.8187 | Alpha: 1.0000
2025-12-11 21:09:55 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_205625/best_policy.pth
2025-12-11 21:11:52 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting Validation...
2025-12-11 21:12:08 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 0: Avg Action Norm: 0.1014 | Avg Movement: 0.000002
2025-12-11 21:12:24 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 1: Avg Action Norm: 0.1013 | Avg Movement: 0.000002
2025-12-11 21:12:40 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 2: Avg Action Norm: 0.1014 | Avg Movement: 0.000002
2025-12-11 21:12:56 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 3: Avg Action Norm: 0.1013 | Avg Movement: 0.000002
2025-12-11 21:13:11 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 4: Avg Action Norm: 0.1013 | Avg Movement: 0.000002
2025-12-11 21:13:11 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Validation Reward: 2880.3096 | Alpha: 0.8824
2025-12-11 21:13:11 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_205625/best_policy.pth
2025-12-11 21:14:22 [WARNING] __main__ - Interrupted.
2025-12-11 21:14:22 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_205625/interrupted_policy.pth
