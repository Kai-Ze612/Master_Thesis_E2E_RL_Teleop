2025-12-11 20:05:37 [INFO] __main__ - Training Configuration (Joint End-to-End):
2025-12-11 20:05:37 [INFO] __main__ -   Delay: HIGH_VARIANCE
2025-12-11 20:05:37 [INFO] __main__ -   Trajectory: figure_8
2025-12-11 20:05:37 [INFO] __main__ -   Total Timesteps: 30000000
2025-12-11 20:05:37 [INFO] __main__ - Creating vectorized environment...
2025-12-11 20:05:38 [INFO] __main__ - Initializing SACTrainer...
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Initial alpha: 1.0000
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Tensorboard logs at: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_200537/tensorboard_sac
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting SAC Training with SHARED ENCODER (Fixed Version)
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Obs Dim: 2334 | Output Dim: 7
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Stage 1 (Encoder + Critic Warmup): 20000 steps
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Stage 2 (RL with Frozen Encoder, Delayed Policy): remaining steps
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Policy Delay: 2
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Initial Alpha: 1.0000
2025-12-11 20:05:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:06:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 2000/20000] Aux Loss: 0.000600 | Critic Loss: 0.8135
2025-12-11 20:06:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 3000/20000] Aux Loss: 0.000729 | Critic Loss: 0.7847
2025-12-11 20:07:36 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 4000/20000] Aux Loss: 0.000343 | Critic Loss: 0.8036
2025-12-11 20:08:15 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 5000/20000] Aux Loss: 0.000284 | Critic Loss: 0.7998
2025-12-11 20:08:55 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 6000/20000] Aux Loss: 0.000180 | Critic Loss: 0.7786
2025-12-11 20:09:33 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 7000/20000] Aux Loss: 0.000184 | Critic Loss: 0.7354
2025-12-11 20:10:12 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 8000/20000] Aux Loss: 0.000137 | Critic Loss: 1.1736
2025-12-11 20:10:50 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 9000/20000] Aux Loss: 0.000148 | Critic Loss: 0.8122
2025-12-11 20:11:29 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 10000/20000] Aux Loss: 0.000120 | Critic Loss: 0.8756
2025-12-11 20:12:09 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 11000/20000] Aux Loss: 0.000115 | Critic Loss: 0.8471
2025-12-11 20:12:47 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 12000/20000] Aux Loss: 0.000136 | Critic Loss: 0.9026
2025-12-11 20:13:26 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 13000/20000] Aux Loss: 0.000114 | Critic Loss: 0.8715
2025-12-11 20:14:05 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 14000/20000] Aux Loss: 0.000128 | Critic Loss: 0.8781
2025-12-11 20:14:43 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 15000/20000] Aux Loss: 0.000109 | Critic Loss: 1.0419
2025-12-11 20:15:22 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 16000/20000] Aux Loss: 0.000123 | Critic Loss: 1.0281
2025-12-11 20:16:02 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 17000/20000] Aux Loss: 0.000489 | Critic Loss: 0.9280
2025-12-11 20:16:40 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 18000/20000] Aux Loss: 0.000142 | Critic Loss: 0.9327
2025-12-11 20:17:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - [Stage 1 - Warmup 19000/20000] Aux Loss: 0.000130 | Critic Loss: 1.0836
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - FREEZING SHARED ENCODER - State Estimator training complete
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - ======================================================================
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Trainable actor params: 847,118
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Trainable critic params: 1,694,722
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Frozen encoder params: 1,366,926
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Current alpha: 1.0000
2025-12-11 20:17:58 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting Validation...
2025-12-11 20:18:14 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 0: Avg Action Norm: 0.3972 | Avg Movement: 0.000322
2025-12-11 20:18:31 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 1: Avg Action Norm: 0.3972 | Avg Movement: 0.000320
2025-12-11 20:18:47 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 2: Avg Action Norm: 0.3972 | Avg Movement: 0.000319
2025-12-11 20:19:03 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 3: Avg Action Norm: 0.3971 | Avg Movement: 0.000321
2025-12-11 20:19:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 4: Avg Action Norm: 0.3970 | Avg Movement: 0.000317
2025-12-11 20:19:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Validation Reward: 1268.1492 | Alpha: 1.0000
2025-12-11 20:19:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_200537/best_policy.pth
2025-12-11 20:21:19 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting Validation...
2025-12-11 20:21:35 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 0: Avg Action Norm: 0.0648 | Avg Movement: 0.000001
2025-12-11 20:21:51 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 1: Avg Action Norm: 0.0648 | Avg Movement: 0.000001
2025-12-11 20:22:07 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 2: Avg Action Norm: 0.0648 | Avg Movement: 0.000001
2025-12-11 20:22:23 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 3: Avg Action Norm: 0.0648 | Avg Movement: 0.000001
2025-12-11 20:22:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 4: Avg Action Norm: 0.0647 | Avg Movement: 0.000001
2025-12-11 20:22:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Validation Reward: 2393.7305 | Alpha: 0.8824
2025-12-11 20:22:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_200537/best_policy.pth
2025-12-11 20:24:39 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Starting Validation...
2025-12-11 20:24:55 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 0: Avg Action Norm: 0.0583 | Avg Movement: 0.000001
2025-12-11 20:25:12 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 1: Avg Action Norm: 0.0583 | Avg Movement: 0.000001
2025-12-11 20:25:28 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm -   Ep 2: Avg Action Norm: 0.0584 | Avg Movement: 0.000001
2025-12-11 20:25:42 [WARNING] __main__ - Interrupted.
2025-12-11 20:25:42 [INFO] E2E_Teleoperation.E2E_RL.sac_training_algorithm - Checkpoint saved: ./rl_training_output/E2E_SAC_HIGH_VARIANCE_figure_8_20251211_200537/interrupted_policy.pth
