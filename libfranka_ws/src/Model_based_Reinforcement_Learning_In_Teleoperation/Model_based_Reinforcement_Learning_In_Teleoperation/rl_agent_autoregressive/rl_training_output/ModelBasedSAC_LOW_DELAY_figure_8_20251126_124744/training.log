2025-11-26 12:47:44 [INFO] __main__ - Training Configuration:
2025-11-26 12:47:44 [INFO] __main__ -   Delay: LOW_DELAY
2025-11-26 12:47:44 [INFO] __main__ -   Trajectory: figure_8
2025-11-26 12:47:44 [INFO] __main__ - Creating vectorized environment...
2025-11-26 12:47:46 [INFO] __main__ - Initializing SACTrainer...
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm - Tensorboard logs at: ./rl_training_output/ModelBasedSAC_LOW_DELAY_figure_8_20251126_124744/tensorboard_sac
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm - ======================================================================
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm - Starting SAC Training (Environment-Centric Prediction)
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm -   Input Dim: 113 | Output Dim: 7
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm - ======================================================================
2025-11-26 12:47:47 [ERROR] __main__ - Error: 
Traceback (most recent call last):
  File "/home/kaize/Downloads/Master_Study_Master_Thesis/libfranka_ws/src/Model_based_Reinforcement_Learning_In_Teleoperation/Model_based_Reinforcement_Learning_In_Teleoperation/rl_agent_autoregressive/train_agent.py", line 99, in train_agent
    trainer.train(total_timesteps=args.timesteps)
  File "/home/kaize/Downloads/Master_Study_Master_Thesis/libfranka_ws/src/Model_based_Reinforcement_Learning_In_Teleoperation/Model_based_Reinforcement_Learning_In_Teleoperation/rl_agent_autoregressive/sac_training_algorithm.py", line 329, in train
    next_obs, rewards_batch, dones_batch, infos_batch = self.env.step(actions_batch)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kaize/venv_thesis/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "/home/kaize/venv_thesis/lib/python3.12/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait
    results = [remote.recv() for remote in self.remotes]
               ^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/usr/lib/python3.12/multiprocessing/connection.py", line 399, in _recv
    raise EOFError
EOFError
2025-11-26 12:47:47 [INFO] Model_based_Reinforcement_Learning_In_Teleoperation.rl_agent_autoregressive.sac_training_algorithm - Checkpoint saved: ./rl_training_output/ModelBasedSAC_LOW_DELAY_figure_8_20251126_124744/crash_policy.pth
