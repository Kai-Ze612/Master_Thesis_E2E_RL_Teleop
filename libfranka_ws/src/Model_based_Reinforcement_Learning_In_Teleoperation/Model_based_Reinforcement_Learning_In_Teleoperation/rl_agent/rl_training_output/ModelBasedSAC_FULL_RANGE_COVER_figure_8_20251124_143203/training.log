2025-11-24 14:32:03 [INFO] __main__ - Training Configuration:
2025-11-24 14:32:03 [INFO] __main__ -   Delay Config: FULL_RANGE_COVER
2025-11-24 14:32:03 [INFO] __main__ -   Trajectory Type: figure_8
2025-11-24 14:32:03 [INFO] __main__ -   Randomize Trajectory: False
2025-11-24 14:32:03 [INFO] __main__ -   Total Timesteps: 3,000,000
2025-11-24 14:32:03 [INFO] __main__ -   Random Seed: None (random)
2025-11-24 14:32:03 [INFO] __main__ - 
2025-11-24 14:32:03 [INFO] __main__ - Creating vectorized environment...
2025-11-24 14:32:04 [INFO] __main__ - Observation Structure (112D):
2025-11-24 14:32:04 [INFO] __main__ -   - Remote state: 14D (position 7D + velocity 7D)
2025-11-24 14:32:04 [INFO] __main__ -   - Remote history: 70D (5 timesteps x 14D)
2025-11-24 14:32:04 [INFO] __main__ -   - LSTM prediction: 14D (position 7D + velocity 7D)
2025-11-24 14:32:04 [INFO] __main__ -   - Current error: 14D (position error 7D + velocity error 7D)
2025-11-24 14:32:04 [INFO] __main__ -   - Total: 113D
2025-11-24 14:32:04 [INFO] __main__ - 
2025-11-24 14:32:04 [INFO] __main__ - Initializing Model-Based SAC trainer...
2025-11-24 14:32:05 [ERROR] __main__ - Failed to initialize trainer: Error(s) in loading state_dict for StateEstimator:
	size mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 14]) from checkpoint, the shape in current model is torch.Size([2048, 14]).
	size mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.weight_ih_l2: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.weight_hh_l2: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l2: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l2: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for prediction_head.0.weight: copying a param with shape torch.Size([256, 257]) from checkpoint, the shape in current model is torch.Size([256, 513]).
Traceback (most recent call last):
  File "/home/kaize/Downloads/Master_Study_Master_Thesis/libfranka_ws/src/Model_based_Reinforcement_Learning_In_Teleoperation/Model_based_Reinforcement_Learning_In_Teleoperation/rl_agent/train_agent.py", line 188, in train_agent
    trainer = SACTrainer(
              ^^^^^^^^^^^
  File "/home/kaize/Downloads/Master_Study_Master_Thesis/libfranka_ws/src/Model_based_Reinforcement_Learning_In_Teleoperation/Model_based_Reinforcement_Learning_In_Teleoperation/rl_agent/sac_training_algorithm.py", line 149, in __init__
    self.state_estimator.load_state_dict(weights['state_estimator_state_dict'])
  File "/home/kaize/venv_thesis/lib/python3.12/site-packages/torch/nn/modules/module.py", line 2629, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for StateEstimator:
	size mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 14]) from checkpoint, the shape in current model is torch.Size([2048, 14]).
	size mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.weight_ih_l2: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.weight_hh_l2: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for lstm.bias_ih_l2: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for lstm.bias_hh_l2: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for prediction_head.0.weight: copying a param with shape torch.Size([256, 257]) from checkpoint, the shape in current model is torch.Size([256, 513]).
